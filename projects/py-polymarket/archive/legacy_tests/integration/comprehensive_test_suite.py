#!/usr/bin/env python3
"""
å®Œæ•´çš„äº¤æ˜“ç³»ç»Ÿç»¼åˆæµ‹è¯•å¥—ä»¶
åŒ…å«åŠŸèƒ½æµ‹è¯•ã€æ€§èƒ½æµ‹è¯•ã€ä»£ç è´¨é‡åˆ†æ
"""

import cProfile
import gc
import io
import os
import pstats
import ssl
import sys
import threading
import time
import types
from concurrent.futures import ThreadPoolExecutor
from core.data_collector import AsyncDataCollector
from core.models import DQNAgent, LSTMTrader, TradingSystem
from core.risk_manager import RiskEngine
from core.strategy import ArbitrageStrategy, MarketMakingStrategy

import aiohttp
import asyncio
import json
import numpy as np
import unittest
from unittest.mock import Mock

import memory_profiler

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'core'))

import unittest
import asyncio
import aiohttp
import ssl
import time
import memory_profiler
import cProfile
import pstats
import io
from unittest.mock import Mock
import numpy as np
import json
from concurrent.futures import ThreadPoolExecutor
import threading
import gc

# é…ç½®è®¾ç½®
OFFLINE_CONFIG = {
    'OFFLINE_MODE': True,
    'PROXY_URL': None
}

ONLINE_CONFIG = {
    'OFFLINE_MODE': False, 
    'PROXY_URL': 'http://brd-customer-hl_74a6e114-zone-residential_proxy1:dddh9tsmw3zh@brd.superproxy.io:33335'
}

class PerformanceTestSuite:
    """æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = {}
        self.setup_modules()
    
    def setup_modules(self):
        """è®¾ç½®æµ‹è¯•æ¨¡å—"""
        import types
        
        # åˆ›å»ºç¦»çº¿é…ç½®
        config_module = types.ModuleType('config')
        config_module.settings = type('Settings', (), OFFLINE_CONFIG)()
        sys.modules['config'] = config_module
        
        # åˆ›å»ºå·¥å…·æ¨¡å—
        utils_module = types.ModuleType('utils')
        proxy_manager_module = types.ModuleType('proxy_manager')
        proxy_manager_module.ProxyManager = Mock()
        utils_module.proxy_manager = proxy_manager_module
        sys.modules['utils'] = utils_module
        sys.modules['utils.proxy_manager'] = proxy_manager_module
        
        # å¯¼å…¥æ ¸å¿ƒæ¨¡å—
        from core.data_collector import AsyncDataCollector
        from core.models import LSTMTrader, DQNAgent, TradingSystem
        from core.risk_manager import RiskEngine
        from core.strategy import MarketMakingStrategy, ArbitrageStrategy
        
        self.modules = {
            'AsyncDataCollector': AsyncDataCollector,
            'LSTMTrader': LSTMTrader,
            'DQNAgent': DQNAgent, 
            'TradingSystem': TradingSystem,
            'RiskEngine': RiskEngine,
            'MarketMakingStrategy': MarketMakingStrategy,
            'ArbitrageStrategy': ArbitrageStrategy
        }

    def run_functionality_tests(self):
        """è¿è¡ŒåŠŸèƒ½æµ‹è¯•"""
        print("ğŸ§ª è¿è¡ŒåŠŸèƒ½æµ‹è¯•...")
        start_time = time.time()
        
        # æµ‹è¯•æ•°æ®æ”¶é›†å™¨
        collector = self.modules['AsyncDataCollector']()
        
        # ç¦»çº¿æ¨¡å¼æµ‹è¯•
        offline_tests = {
            'market_data_fetch': self._test_market_data_fetch(collector),
            'order_book_fetch': self._test_order_book_fetch(collector),
            'sync_method': self._test_sync_method(collector)
        }
        
        # æµ‹è¯•é£é™©ç®¡ç†
        risk_engine = self.modules['RiskEngine']()
        risk_tests = {
            'var_calculation': self._test_var_calculation(risk_engine),
            'liquidity_check': self._test_liquidity_check(risk_engine),
            'order_validation': self._test_order_validation(risk_engine)
        }
        
        # æµ‹è¯•äº¤æ˜“ç­–ç•¥
        market_making = self.modules['MarketMakingStrategy'](spread=0.02, balance=10000)
        arbitrage = self.modules['ArbitrageStrategy'](threshold=0.05)
        
        strategy_tests = {
            'market_making_orders': self._test_market_making(market_making),
            'arbitrage_detection': self._test_arbitrage(arbitrage),
            'position_sizing': self._test_position_sizing(market_making)
        }
        
        end_time = time.time()
        
        self.results['functionality'] = {
            'offline_tests': offline_tests,
            'risk_tests': risk_tests,
            'strategy_tests': strategy_tests,
            'total_time': end_time - start_time,
            'success_rate': self._calculate_success_rate([offline_tests, risk_tests, strategy_tests])
        }
        
        print(f"âœ… åŠŸèƒ½æµ‹è¯•å®Œæˆ ({end_time - start_time:.2f}s)")
        return self.results['functionality']

    def run_performance_benchmarks(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        start_time = time.time()
        
        # å†…å­˜ä½¿ç”¨æµ‹è¯•
        memory_before = memory_profiler.memory_usage()[0]
        
        # CPUå¯†é›†å‹æµ‹è¯•
        cpu_results = self._benchmark_cpu_intensive_operations()
        
        # I/Oå¯†é›†å‹æµ‹è¯•  
        io_results = self._benchmark_io_operations()
        
        # å¹¶å‘æµ‹è¯•
        concurrency_results = self._benchmark_concurrency()
        
        # å†…å­˜æµ‹è¯•
        memory_after = memory_profiler.memory_usage()[0]
        memory_usage = memory_after - memory_before
        
        end_time = time.time()
        
        self.results['performance'] = {
            'cpu_benchmarks': cpu_results,
            'io_benchmarks': io_results,
            'concurrency_benchmarks': concurrency_results,
            'memory_usage': memory_usage,
            'total_time': end_time - start_time
        }
        
        print(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ ({end_time - start_time:.2f}s)")
        return self.results['performance']

    def run_code_quality_analysis(self):
        """ä»£ç è´¨é‡åˆ†æ"""
        print("ğŸ” ä»£ç è´¨é‡åˆ†æ...")
        start_time = time.time()
        
        # åˆ†æä»£ç ç»“æ„
        code_metrics = self._analyze_code_structure()
        
        # åˆ†æå¤æ‚åº¦
        complexity_metrics = self._analyze_complexity()
        
        # åˆ†æä¾èµ–å…³ç³»
        dependency_metrics = self._analyze_dependencies()
        
        end_time = time.time()
        
        self.results['code_quality'] = {
            'structure_metrics': code_metrics,
            'complexity_metrics': complexity_metrics,
            'dependency_metrics': dependency_metrics,
            'analysis_time': end_time - start_time
        }
        
        print(f"âœ… ä»£ç è´¨é‡åˆ†æå®Œæˆ ({end_time - start_time:.2f}s)")
        return self.results['code_quality']

    def _test_market_data_fetch(self, collector):
        """æµ‹è¯•å¸‚åœºæ•°æ®è·å–"""
        try:
            markets = asyncio.run(collector.fetch_markets())
            return {
                'success': True,
                'data_count': len(markets),
                'data_structure_valid': all(key in markets[0] for key in ['market_id', 'bid', 'ask']) if markets else False
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_order_book_fetch(self, collector):
        """æµ‹è¯•è®¢å•ç°¿è·å–"""
        try:
            order_book = asyncio.run(collector.fetch_order_book("test_market"))
            return {
                'success': True,
                'has_bids': 'bids' in order_book,
                'has_asks': 'asks' in order_book
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_sync_method(self, collector):
        """æµ‹è¯•åŒæ­¥æ–¹æ³•"""
        try:
            markets = collector.fetch_all_active_market_data()
            return {
                'success': True,
                'data_count': len(markets)
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_var_calculation(self, risk_engine):
        """æµ‹è¯•VaRè®¡ç®—"""
        try:
            order = {'size': 100}
            portfolio = {
                'returns': np.random.normal(0, 0.01, 200),
                'balance': 10000
            }
            result = risk_engine._calculate_var(order, portfolio)
            return {
                'success': True,
                'result_type': type(result).__name__,
                'is_boolean': isinstance(result, bool)
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_liquidity_check(self, risk_engine):
        """æµ‹è¯•æµåŠ¨æ€§æ£€æŸ¥"""
        try:
            order = {'size': 500}
            portfolio = {'balance': 10000}
            result = risk_engine._check_liquidity(order, portfolio)
            return {
                'success': True,
                'result': result,
                'expected': True  # 5% < 10%
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_order_validation(self, risk_engine):
        """æµ‹è¯•è®¢å•éªŒè¯"""
        try:
            order = {'size': 100}
            portfolio = {
                'returns': np.random.normal(0, 0.01, 100),
                'balance': 10000
            }
            result = risk_engine.validate_order(order, portfolio)
            return {
                'success': True,
                'validation_passed': result
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_market_making(self, strategy):
        """æµ‹è¯•åšå¸‚ç­–ç•¥"""
        try:
            market_data = {
                'bid': 0.45,
                'ask': 0.55,
                'high': 0.6,
                'low': 0.4,
                'market_id': 'TEST-1'
            }
            orders = strategy.generate_orders(market_data)
            return {
                'success': True,
                'has_action': 'action' in orders,
                'has_prices': all(key in orders for key in ['bid', 'ask']),
                'spread_correct': orders['ask'] > orders['bid']
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_arbitrage(self, strategy):
        """æµ‹è¯•å¥—åˆ©ç­–ç•¥"""
        try:
            market_a = {'price': 0.45, 'market_id': 'MARKET-A'}
            market_b = {'price': 0.55, 'market_id': 'MARKET-B'}
            opportunity = strategy.find_opportunities(market_a, market_b)
            return {
                'success': True,
                'opportunity_found': opportunity is not None,
                'correct_direction': opportunity['buy_market'] == 'MARKET-A' if opportunity else None
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _test_position_sizing(self, strategy):
        """æµ‹è¯•å¤´å¯¸è®¡ç®—"""
        try:
            market_data = {'high': 0.6, 'low': 0.4, 'bid': 0.45, 'ask': 0.55}
            size = strategy._calculate_position_size(market_data)
            return {
                'success': True,
                'size_positive': size > 0,
                'size_reasonable': 0 < size < 10000
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _benchmark_cpu_intensive_operations(self):
        """CPUå¯†é›†å‹æ“ä½œåŸºå‡†æµ‹è¯•"""
        results = {}
        
        # æµ‹è¯•NumPyæ•°ç»„æ“ä½œ
        start = time.time()
        large_array = np.random.random((1000, 1000))
        matrix_mult = np.dot(large_array, large_array)
        results['numpy_matrix_mult'] = time.time() - start
        
        # æµ‹è¯•é£é™©è®¡ç®—
        start = time.time()
        for _ in range(1000):
            returns = np.random.normal(0, 0.01, 100)
            var = np.percentile(returns, 5)
        results['var_calculations_1000x'] = time.time() - start
        
        # æµ‹è¯•ç­–ç•¥è®¡ç®—
        start = time.time()
        strategy = self.modules['MarketMakingStrategy']()
        for _ in range(1000):
            market_data = {
                'bid': np.random.uniform(0.4, 0.6),
                'ask': np.random.uniform(0.6, 0.8),
                'high': 0.8,
                'low': 0.4
            }
            orders = strategy.generate_orders(market_data)
        results['strategy_calculations_1000x'] = time.time() - start
        
        return results

    def _benchmark_io_operations(self):
        """I/Oæ“ä½œåŸºå‡†æµ‹è¯•"""
        results = {}
        
        # æµ‹è¯•å¼‚æ­¥å¸‚åœºæ•°æ®è·å–
        start = time.time()
        collector = self.modules['AsyncDataCollector']()
        for _ in range(10):
            markets = asyncio.run(collector.fetch_markets())
        results['market_data_fetch_10x'] = time.time() - start
        
        # æµ‹è¯•åŒæ­¥æ–¹æ³•æ€§èƒ½
        start = time.time()
        for _ in range(10):
            markets = collector.fetch_all_active_market_data()
        results['sync_method_10x'] = time.time() - start
        
        return results

    def _benchmark_concurrency(self):
        """å¹¶å‘æ€§èƒ½æµ‹è¯•"""
        results = {}
        
        # æµ‹è¯•å¼‚æ­¥å¹¶å‘
        async def concurrent_fetch():
            collector = self.modules['AsyncDataCollector']()
            tasks = [collector.fetch_markets() for _ in range(10)]
            return await asyncio.gather(*tasks)
        
        start = time.time()
        results_list = asyncio.run(concurrent_fetch())
        results['async_concurrent_fetch'] = time.time() - start
        
        # æµ‹è¯•çº¿ç¨‹æ± å¹¶å‘
        def sync_task():
            collector = self.modules['AsyncDataCollector']()
            return collector.fetch_all_active_market_data()
        
        start = time.time()
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(sync_task) for _ in range(10)]
            thread_results = [f.result() for f in futures]
        results['thread_pool_concurrent'] = time.time() - start
        
        return results

    def _analyze_code_structure(self):
        """åˆ†æä»£ç ç»“æ„"""
        metrics = {}
        
        # åˆ†ææ–‡ä»¶å¤§å°
        core_files = ['data_collector.py', 'models.py', 'risk_manager.py', 'strategy.py']
        file_sizes = {}
        
        for file in core_files:
            file_path = os.path.join('core', file)
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    lines = f.readlines()
                    file_sizes[file] = {
                        'total_lines': len(lines),
                        'code_lines': len([l for l in lines if l.strip() and not l.strip().startswith('#')]),
                        'comment_lines': len([l for l in lines if l.strip().startswith('#')])
                    }
        
        metrics['file_metrics'] = file_sizes
        
        # åˆ†æç±»å’Œå‡½æ•°æ•°é‡
        module_analysis = {}
        for name, module_class in self.modules.items():
            if hasattr(module_class, '__dict__'):
                methods = [attr for attr in dir(module_class) if not attr.startswith('_')]
                module_analysis[name] = {
                    'public_methods': len(methods),
                    'total_attributes': len(dir(module_class))
                }
        
        metrics['module_analysis'] = module_analysis
        
        return metrics

    def _analyze_complexity(self):
        """åˆ†æä»£ç å¤æ‚åº¦"""
        metrics = {}
        
        # ç®€å•çš„å¤æ‚åº¦åº¦é‡
        complexity_scores = {}
        
        # åˆ†æå„æ¨¡å—çš„ä¼°ç®—å¤æ‚åº¦
        for name, module_class in self.modules.items():
            score = 0
            methods = [attr for attr in dir(module_class) if not attr.startswith('_')]
            
            # åŸºäºæ–¹æ³•æ•°é‡çš„å¤æ‚åº¦
            score += len(methods) * 2
            
            # åŸºäºç»§æ‰¿çš„å¤æ‚åº¦
            if hasattr(module_class, '__bases__'):
                score += len(module_class.__bases__) * 5
            
            complexity_scores[name] = score
        
        metrics['complexity_scores'] = complexity_scores
        metrics['average_complexity'] = np.mean(list(complexity_scores.values()))
        
        return metrics

    def _analyze_dependencies(self):
        """åˆ†æä¾èµ–å…³ç³»"""
        metrics = {}
        
        # åˆ†æimportä¾èµ–
        import_counts = {}
        
        core_files = ['data_collector.py', 'models.py', 'risk_manager.py', 'strategy.py']
        
        for file in core_files:
            file_path = os.path.join('core', file)
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    content = f.read()
                    import_lines = [line for line in content.split('\n') if line.strip().startswith('import') or line.strip().startswith('from')]
                    import_counts[file] = len(import_lines)
        
        metrics['import_dependencies'] = import_counts
        metrics['average_imports'] = np.mean(list(import_counts.values())) if import_counts else 0
        
        return metrics

    def _calculate_success_rate(self, test_groups):
        """è®¡ç®—æˆåŠŸç‡"""
        total_tests = 0
        successful_tests = 0
        
        for group in test_groups:
            for test_name, result in group.items():
                total_tests += 1
                if isinstance(result, dict) and result.get('success', False):
                    successful_tests += 1
        
        return (successful_tests / total_tests * 100) if total_tests > 0 else 0

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ äº¤æ˜“ç³»ç»Ÿç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        # åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š
        if 'functionality' in self.results:
            func_results = self.results['functionality']
            print(f"\nğŸ“‹ åŠŸèƒ½æµ‹è¯•ç»“æœ:")
            print(f"   æˆåŠŸç‡: {func_results['success_rate']:.1f}%")
            print(f"   æ‰§è¡Œæ—¶é—´: {func_results['total_time']:.2f}s")
            
            # è¯¦ç»†ç»“æœ
            for category, tests in func_results.items():
                if isinstance(tests, dict) and category.endswith('_tests'):
                    print(f"\n   {category.replace('_', ' ').title()}:")
                    for test_name, result in tests.items():
                        if isinstance(result, dict):
                            status = "âœ…" if result.get('success', False) else "âŒ"
                            print(f"     {status} {test_name}")
        
        # æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
        if 'performance' in self.results:
            perf_results = self.results['performance']
            print(f"\nâš¡ æ€§èƒ½æµ‹è¯•ç»“æœ:")
            print(f"   æ€»æ‰§è¡Œæ—¶é—´: {perf_results['total_time']:.2f}s")
            print(f"   å†…å­˜ä½¿ç”¨: {perf_results['memory_usage']:.2f} MB")
            
            print(f"\n   CPUåŸºå‡†æµ‹è¯•:")
            for test_name, time_taken in perf_results['cpu_benchmarks'].items():
                print(f"     {test_name}: {time_taken:.4f}s")
            
            print(f"\n   I/OåŸºå‡†æµ‹è¯•:")
            for test_name, time_taken in perf_results['io_benchmarks'].items():
                print(f"     {test_name}: {time_taken:.4f}s")
            
            print(f"\n   å¹¶å‘æµ‹è¯•:")
            for test_name, time_taken in perf_results['concurrency_benchmarks'].items():
                print(f"     {test_name}: {time_taken:.4f}s")
        
        # ä»£ç è´¨é‡æŠ¥å‘Š
        if 'code_quality' in self.results:
            quality_results = self.results['code_quality']
            print(f"\nğŸ” ä»£ç è´¨é‡åˆ†æ:")
            print(f"   åˆ†ææ—¶é—´: {quality_results['analysis_time']:.2f}s")
            
            # æ–‡ä»¶ç»“æ„
            if 'file_metrics' in quality_results['structure_metrics']:
                print(f"\n   æ–‡ä»¶ç»“æ„åˆ†æ:")
                for file, metrics in quality_results['structure_metrics']['file_metrics'].items():
                    print(f"     {file}: {metrics['total_lines']} è¡Œ ({metrics['code_lines']} ä»£ç , {metrics['comment_lines']} æ³¨é‡Š)")
            
            # å¤æ‚åº¦åˆ†æ
            if 'complexity_scores' in quality_results['complexity_metrics']:
                print(f"\n   å¤æ‚åº¦åˆ†æ:")
                print(f"     å¹³å‡å¤æ‚åº¦: {quality_results['complexity_metrics']['average_complexity']:.1f}")
                for module, score in quality_results['complexity_metrics']['complexity_scores'].items():
                    print(f"     {module}: {score}")
        
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        self._generate_optimization_recommendations()
        
        print("="*80)

    def _generate_optimization_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        
        recommendations = []
        
        if 'performance' in self.results:
            perf_results = self.results['performance']
            
            # å†…å­˜ä¼˜åŒ–å»ºè®®
            if perf_results['memory_usage'] > 50:
                recommendations.append("å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œè€ƒè™‘ä½¿ç”¨ç”Ÿæˆå™¨å’Œ__slots__ä¼˜åŒ–")
            
            # CPUä¼˜åŒ–å»ºè®®
            cpu_benchmarks = perf_results['cpu_benchmarks']
            if cpu_benchmarks.get('numpy_matrix_mult', 0) > 1.0:
                recommendations.append("NumPyæ“ä½œè¾ƒæ…¢ï¼Œè€ƒè™‘ä½¿ç”¨æ›´å°çš„æ•°æ®é›†æˆ–GPUåŠ é€Ÿ")
            
            if cpu_benchmarks.get('var_calculations_1000x', 0) > 0.5:
                recommendations.append("VaRè®¡ç®—å¯ä»¥é€šè¿‡é¢„è®¡ç®—å’Œç¼“å­˜ä¼˜åŒ–")
            
            # I/Oä¼˜åŒ–å»ºè®®
            io_benchmarks = perf_results['io_benchmarks']
            if io_benchmarks.get('market_data_fetch_10x', 0) > 2.0:
                recommendations.append("å¸‚åœºæ•°æ®è·å–è¾ƒæ…¢ï¼Œè€ƒè™‘è¿æ¥æ± å’Œç¼“å­˜")
            
            # å¹¶å‘ä¼˜åŒ–å»ºè®®
            concurrent_benchmarks = perf_results['concurrency_benchmarks']
            async_time = concurrent_benchmarks.get('async_concurrent_fetch', 0)
            thread_time = concurrent_benchmarks.get('thread_pool_concurrent', 0)
            
            if async_time > thread_time:
                recommendations.append("å¼‚æ­¥æ€§èƒ½ä½äºçº¿ç¨‹æ± ï¼Œæ£€æŸ¥å¼‚æ­¥å®ç°")
            elif thread_time > async_time * 2:
                recommendations.append("çº¿ç¨‹æ± å¼€é”€è¾ƒå¤§ï¼Œä¼˜å…ˆä½¿ç”¨å¼‚æ­¥")
        
        # ä»£ç è´¨é‡å»ºè®®
        if 'code_quality' in self.results:
            quality_results = self.results['code_quality']
            
            avg_complexity = quality_results['complexity_metrics'].get('average_complexity', 0)
            if avg_complexity > 50:
                recommendations.append("ä»£ç å¤æ‚åº¦è¾ƒé«˜ï¼Œè€ƒè™‘é‡æ„å’Œæ¨¡å—åŒ–")
            
            avg_imports = quality_results['dependency_metrics'].get('average_imports', 0)
            if avg_imports > 10:
                recommendations.append("ä¾èµ–è¾ƒå¤šï¼Œè€ƒè™‘å‡å°‘ä¸å¿…è¦çš„å¯¼å…¥")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "å®ç°è¿æ¥æ± ç®¡ç†å‡å°‘ç½‘ç»œå¼€é”€",
            "æ·»åŠ ç»“æœç¼“å­˜å‡å°‘é‡å¤è®¡ç®—", 
            "ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å‚æ•°",
            "å®ç°å¥åº·æ£€æŸ¥å’Œç›‘æ§",
            "æ·»åŠ æ›´å¤šå•å…ƒæµ‹è¯•è¦†ç›–è¾¹ç•Œæƒ…å†µ"
        ])
        
        for i, rec in enumerate(recommendations[:8], 1):
            print(f"   {i}. {rec}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨äº¤æ˜“ç³»ç»Ÿç»¼åˆæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = PerformanceTestSuite()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_suite.run_functionality_tests()
    test_suite.run_performance_benchmarks()
    test_suite.run_code_quality_analysis()
    
    # ç”ŸæˆæŠ¥å‘Š
    test_suite.generate_comprehensive_report()
    
    # ä¿å­˜ç»“æœ
    with open('comprehensive_test_results.json', 'w') as f:
        json.dump(test_suite.results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° comprehensive_test_results.json")

if __name__ == "__main__":
    main()