# agent_with_mcp_evm.py
# EVM ç‰ˆæœ¬çš„ AI ä»£ç† - ç‹¬ç«‹é¡¹ç›®

# éšè— gRPC å’Œ MCP è­¦å‘Š
import os
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GRPC_TRACE'] = ''
os.environ['PYTHONWARNINGS'] = 'ignore'

import grpc
import asyncio
import json
import traceback
import sys
from dotenv import load_dotenv

import agent_pb2
import agent_pb2_grpc

# LLM
from langchain_google_genai import ChatGoogleGenerativeAI

# LangChain agent (ä½¿ç”¨ create_react_agent)
from langgraph.prebuilt import create_react_agent

# LangChain core history (ç”¨äºä¼šè¯ç®¡ç†)
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage

# MCP adapters
from langchain_mcp_adapters.client import MultiServerMCPClient



# ========= ç¯å¢ƒå˜é‡ =========
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GOOGLE_API_KEY")

# ========= LLM =========
# é…ç½®ç³»ç»Ÿæç¤ºè¯
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ EVM/ä»¥å¤ªåŠåŒºå—é“¾åŠ©æ‰‹ã€‚

é‡è¦è§„åˆ™ï¼š
1. å§‹ç»ˆä»¥çº¯æ–‡æœ¬æ ¼å¼å›ç­”ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•JSONç»“æ„æˆ–å¤æ‚æ ¼å¼
2. å½“ä½ ä½¿ç”¨å·¥å…·æŸ¥è¯¢æ•°æ®æ—¶ï¼Œè¯·ç†è§£å¹¶æ€»ç»“è¿”å›çš„ç»“æœï¼Œç”¨æ¸…æ™°ã€å‹å¥½çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·
3. å·¥å…·è¿”å›çš„æ•°æ®å·²ç»æ˜¯çº¯æ–‡æœ¬æ ¼å¼ï¼Œè¯·ç›´æ¥è§£æå’Œæ€»ç»“ï¼Œä¸è¦æ˜¾ç¤ºåŸå§‹çš„JSONæ•°æ®
4. å¯¹äºä»£å¸ä½™é¢æŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯ï¼šä»£å¸åç§°ã€æ•°é‡ã€ä»·å€¼ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œç”¨ç®€æ´çš„åˆ—è¡¨æˆ–è¡¨æ ¼å‘ˆç°
5. å¯¹äºä»·æ ¼æŸ¥è¯¢ï¼Œç”¨ç®€æ´çš„æ ¼å¼å±•ç¤ºä»·æ ¼å’Œæ—¶é—´
6. å¯¹äº NFT æŸ¥è¯¢ï¼Œæ€»ç»“ NFT çš„æ•°é‡å’Œä¸»è¦æ”¶è—
7. å¯¹äºäº¤æ˜“å†å²ï¼Œåˆ—å‡ºé‡è¦çš„äº¤æ˜“ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ—¶é—´ã€é‡‘é¢ã€äº¤æ˜“å“ˆå¸Œç­‰
8. ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šå’Œå‹å¥½çš„è¯­æ°”
9. å§‹ç»ˆä»¥ç”¨æˆ·å‹å¥½çš„æ–¹å¼å‘ˆç°æ•°æ®ï¼Œé¿å…æ˜¾ç¤ºæŠ€æœ¯ç»†èŠ‚
10. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿çš„è§£é‡Š

ç¤ºä¾‹ï¼š
âœ… å¾ˆå¥½ï¼šè¯¥åœ°å€å…±æœ‰ 96 ç§ä¸åŒçš„ä»£å¸ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
  ğŸ’° ETH: 0.788 æšï¼ˆä»·å€¼ $3,954.63ï¼‰
  ğŸ’° POL: 400,000,000 æš
  ğŸ’° ANON: 199,999 æš
  ä»¥åŠå…¶ä»– 93 ç§ä»£å¸ã€‚

âœ… å¾ˆå¥½ï¼šæœ€è¿‘çš„äº¤æ˜“è®°å½•ï¼š
  ğŸ“… 2024-01-15: è½¬å…¥ 0.5 ETH
  ğŸ“… 2024-01-14: è½¬å‡º 100 USDC
  ğŸ“… 2024-01-13: è½¬å…¥ 1.2 ETH

âŒ é¿å…ï¼šæ˜¾ç¤ºå¤æ‚çš„JSONç»“æ„æˆ–æŠ€æœ¯ç»†èŠ‚
"""

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=google_api_key,
    temperature=0.2,
)




# ========= ä¼šè¯å†å² =========
store = {}


def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]


# ========= gRPC Servicer =========
class AgentService(agent_pb2_grpc.AgentServiceServicer):
    def __init__(self, agent, session_getter, mcp_client):
        self.agent = agent
        self.get_session_history = session_getter
        self.mcp_client = mcp_client

    async def Chat(self, request, context):
        user_input = request.message
        session_id = "test-session"
        print(f"[Agent] æ”¶åˆ° Chat (session={session_id}): {user_input}")

        session_history = self.get_session_history(session_id)

        try:
            # å°†å†å²æ¶ˆæ¯å’Œå½“å‰ç”¨æˆ·è¾“å…¥æ„é€ æˆä»£ç†æ‰€éœ€çš„æ ¼å¼
            messages = []
            
            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆä»…åœ¨é¦–æ¬¡å¯¹è¯æ—¶ï¼‰
            if len(session_history.messages) == 0:
                from langchain_core.messages import SystemMessage
                messages.append(SystemMessage(content=system_prompt))
            
            # æ·»åŠ å†å²æ¶ˆæ¯
            for msg in session_history.messages:
                if msg.type == "human":
                    messages.append(HumanMessage(content=msg.content))
                elif msg.type == "ai":
                    messages.append(AIMessage(content=msg.content))
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append(HumanMessage(content=user_input))

            # è°ƒç”¨ä»£ç†
            agent_response = await self.agent.ainvoke({"messages": messages})

            # ä»£ç†çš„å“åº”æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­ "messages" åŒ…å«äº†æ–°çš„æ¶ˆæ¯åˆ—è¡¨
            new_messages = agent_response["messages"]

            # å°†æ–°çš„æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•ä¸­
            for msg in new_messages[len(messages):]:  # åªæ·»åŠ æ–°ç”Ÿæˆçš„æ¶ˆæ¯
                if isinstance(msg, HumanMessage):
                    session_history.add_user_message(msg.content)
                elif isinstance(msg, AIMessage):
                    session_history.add_ai_message(msg.content)

                    # å®‰å…¨åœ°å°†å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    content_str = ""
                    if isinstance(msg.content, str):
                        content_str = msg.content
                    elif isinstance(msg.content, (list, dict)):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯MCPå·¥å…·å“åº”æ ¼å¼
                        if isinstance(msg.content, dict) and "content" in msg.content:
                            # æå–MCPå·¥å…·å“åº”ä¸­çš„çº¯æ–‡æœ¬å†…å®¹
                            content_list = msg.content.get("content", [])
                            if isinstance(content_list, list) and len(content_list) > 0:
                                first_content = content_list[0]
                                if isinstance(first_content, dict) and "text" in first_content:
                                    content_str = first_content["text"]
                                else:
                                    content_str = str(first_content)
                            else:
                                content_str = json.dumps(msg.content, ensure_ascii=False, indent=2)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯AIå›ç­”çš„å¤æ‚JSONæ ¼å¼
                        elif isinstance(msg.content, list) and len(msg.content) > 0:
                            first_item = msg.content[0]
                            if isinstance(first_item, dict) and "type" in first_item and "text" in first_item:
                                # æå–çº¯æ–‡æœ¬å†…å®¹ï¼Œå¿½ç•¥extraså’Œsignature
                                content_str = first_item.get("text", "")
                            else:
                                content_str = str(first_item)
                        else:
                            # å¦‚æœæ˜¯å…¶ä»–ç»“æ„åŒ–æ•°æ®ï¼Œè½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                            content_str = json.dumps(msg.content, ensure_ascii=False, indent=2)
                    else:
                        # å…¶ä»–ç±»å‹ï¼Œå¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²
                        content_str = str(msg.content)

                    # æŒ‰å­—ç¬¦æµå¼è¾“å‡ºï¼Œç¡®ä¿å…¼å®¹æ€§
                    for char in content_str:
                        yield agent_pb2.ChatResponse(content=char)

            yield agent_pb2.ChatResponse(content="[STREAM_END]")

        except Exception as e:
            error_msg = f"Chat å¤„ç†å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}", file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            await context.abort(grpc.StatusCode.UNKNOWN, error_msg)

    async def ExecuteAction(self, request, context):
        print(f"[Agent] æ”¶åˆ° ExecuteAction: {request.action} {request.params}")
        action_result = {
            "executed_action": request.action,
            "params": json.loads(request.params) if request.params else {},
            "status": "ok"
        }
        return agent_pb2.ActionResponse(
            success=True,
            result=json.dumps(action_result)
        )


# ========= ä¸»æœåŠ¡å¯åŠ¨ =========
async def serve():
    # --- ä»ç¯å¢ƒå˜é‡å®‰å…¨åœ°è¯»å–ç§é’¥ ---
    private_key = os.getenv("EVM_PRIVATE_KEY")  # âœ… æ”¹ä¸º EVM_PRIVATE_KEY
    if not private_key:
        print("[ERROR] EVM_PRIVATE_KEY environment variable not set. This service should be launched by evm-cli.", file=sys.stderr)
        sys.exit(1)
    
    # --- ç«‹å³ä»å½“å‰ç¯å¢ƒç§»é™¤ï¼Œå‡å°‘æš´éœ² ---
    try:
        del os.environ["EVM_PRIVATE_KEY"]  # âœ… æ”¹ä¸º EVM_PRIVATE_KEY
    except KeyError:
        pass # å¦‚æœé”®ä¸å­˜åœ¨ï¼Œä¹Ÿæ— å¦¨

    # Get the absolute path to the project root directory relative to this script's location.
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, os.pardir))

    # âœ… EVM ä¸“ç”¨é…ç½® - ä½¿ç”¨æ–°çš„ Alchemy MCP Server (Node.jsç‰ˆæœ¬)
    # æŸ¥æ‰¾ node å‘½ä»¤çš„å®Œæ•´è·¯å¾„
    import shutil
    node_path = shutil.which("node") or os.path.expanduser("~/.nvm/versions/node/v20.19.3/bin/node")
    if not os.path.exists(node_path if node_path else ""):
        node_path = "/usr/local/bin/node"  # å¤‡ç”¨è·¯å¾„
    
    mcp_servers = {
        "alchemy": {  # Alchemyå®˜æ–¹MCPæœåŠ¡å™¨
            "command": node_path,
            "args": [os.path.join(PROJECT_ROOT, "evm-mcp", "dist", "index.js")],
            "transport": "stdio",
            # --- ä¼ é€’ Alchemy API Key ç»™ MCP å­è¿›ç¨‹ ---
            "env": {
                "ALCHEMY_API_KEY": os.getenv("ALCHEMY_API_KEY", "9FIy7L0mx0c7ZhSAOmpWwrUKPAaKADjm"),
                "EVM_PRIVATE_KEY": private_key,
            }
        }
    }

    client = MultiServerMCPClient(mcp_servers)
    print("[MCP] MultiServerMCPClient å·²åˆå§‹åŒ–ï¼Œå¼€å§‹åŠ è½½ Alchemy å·¥å…·...")
    tools = await client.get_tools()
    print(f"[MCP] å·²åŠ è½½ {len(tools)} ä¸ª Alchemy å·¥å…·: {[getattr(t, 'name', str(t)) for t in tools]}")

    # åˆ›å»ºä»£ç†
    # æ³¨æ„ï¼šlanggraph çš„ create_react_agent ä¼šè‡ªåŠ¨ä½¿ç”¨ LLM çš„ç³»ç»Ÿæç¤º
    # æˆ‘ä»¬éœ€è¦åœ¨ LLM åˆå§‹åŒ–æ—¶è®¾ç½®ç³»ç»Ÿæ¶ˆæ¯
    agent = create_react_agent(llm, tools)

    server = grpc.aio.server()
    servicer = AgentService(agent, get_session_history, client)
    agent_pb2_grpc.add_AgentServiceServicer_to_server(servicer, server)
    server.add_insecure_port("[::]:50051")
    await server.start()
    print("[Agent] EVM Agent async gRPC æœåŠ¡å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ 50051")
    await server.wait_for_termination()


if __name__ == "__main__":
    try:
        asyncio.run(serve())
    except KeyboardInterrupt:
        print("é€€å‡ºä¸­...")

